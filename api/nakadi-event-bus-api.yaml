swagger: '2.0'
info:
  title: Nakadi Event Bus API Definition
  description: |
    -----------
    Definitions
    -----------
    Nakadi at its core aims at being a generic and content-agnostic event broker with a convenient API. By doing this, Nakadi abstracts away, as much as possible, details of the backing messaging infrastructure. The single currently supported messaging middleware is Kafka (Kinesis is planned for the future).

    Nakadi itself will impose as little as possible in the event structure and its contents. Nevertheless, Nakadi provides for extensible validation of incoming messages based on its structure and content. This means that, although Nakadi strives to act transparently as a message broker, it provides means to safeguard the content quality of the events flowing in.

    Similar approach is used to support enrichment of the content of events, where certain pieces of information on the events are set upon reception on Nakadi. Besides this possibility of content enrichment, Nakadi will never manipulate the content of events.

    From the perspective of operation of Nakadi, an event and a management APIs are provided. The **event API** contains the operations related to the communication streams (i.e. sending and receiving events, in its different forms).

    The management of the communication streams is offered by Nakadi in 2 distinct levels of abstraction, named low-level and hi-level APIs. The **low-level API** delegates to the consumer the whole responsibility of tracking the pointer of consumption of a stream, as well as the partitioning. On the other hand, with this responsibility one gains the possibility of having full control of consumption and very little overhead on Nakadi's side.

    The alternative to low-level is the **high-level API**, where consumers have a "stateful stream", where Nakadi assumes the responsibility of managing the pointer tracking of the streams vis-a-vis each subscribed consumer. *Nakadi partitions the data respecting a `PartitioningStrategy` that is set per resource/topic (details TBD).*

    The **management API** in Nakadi contains methods related to registration and configuration of `Topic`s and of `EventType`s, among others. *The processes involved in the registration of `Topic`s and assignment of responsbility over `EventType`s to them, as well as the configuration of its **format validation**, are still to be defined.*

    Although the APIs are semantically grouped as relevant for event and management purposes, they interact in important ways. Most important is that the steering of validation and enrichment of messages of a given EventType on a Topic are defined via the management API. Therefore understanding of the event API is not complete without the management API.


    Scope and status of this document
    -------------------------------

    The present API specification is in **draft** state and is subject to change.

    The present document's purpose is the specification of the API and behaviour of Nakadi from a client perspective, i.e. as a Producer or Consumer of events.

    In this document, ready for review, are included:

    * Low-level API communication API
    * Stantardised event format (see #/definitions/Event)
    * Partition strategy: event store will infer the partition from the `partitioning_key` in the message body

    Other aspects of the Event Bus are at this moment to be defined and otherwise specificied, not included in this version of this specification.

    Notable omissions here are:
    * The process of creating a `Topic` and definition of the related `EventType`s is not fully defined and its details will be added as it becomes more clear.
    * Certain aspects of the validation procedures of incoming events might not be possible to finalize until the preceding point is pending.
    * The specific ways of defining the validation and enrichment of events are unspecified at this point.
    * The contract between Nakadi and clients in the context of the high-level API.
    * Submission of events to topics in batched manner.
    *

  version: '0.4'
  contact:
    name: Team Aruha @ Zalando
    email: team-aruha+nakadi-maintainers@zalando.de
schemes:
  - https
consumes:
  - application/json
produces:
  - application/json
securityDefinitions:
  oauth2:
    type: oauth2
    flow: implicit
    authorizationUrl: 'https://auth.example.com/oauth2/tokeninfo'

paths:
  /metrics:
    get:
      tags:
        - monitoring
      summary: Get monitoring metrics
      responses:
        '200':
          description: Metrics data
          schema:
            $ref: '#/definitions/Metrics'
        '401':
          description: User is not authenticated
          schema:
            $ref: '#/definitions/Problem'
        '503':
          description: Not available
          schema:
            $ref: '#/definitions/Problem'
  /topics:
    get:
      description: Lists all known `Topics` of this Nakadi cluster
      tags:
        - monitoring
        - management-api
      responses:
        '200':
          description: The request was successful. Returns a list `Topic`s in the response body.
          schema:
            type: array
            description: An array of topics
            items:
              $ref: '#/definitions/Topic'
        '401':
          description: User is not authenticated
          schema:
            $ref: '#/definitions/Problem'
        '503':
          description: Not available
          schema:
            $ref: '#/definitions/Problem'


    post:
      tags:
        - management-api
        - draft
      description: |
        Creates a topic.

        **To be defined:** How and when are `EventType`s defined and bound to a `Topic`?
      parameters:
        - name: topic
          in: body
          description: Topic that must be created
          schema:
            type: object
            $ref: '#/definitions/Topic'
          required: true
      responses:
        '200':
          description: The request was successful. Returns a list `Topic`s in the response body.
          schema:
            type: array
            description: An array of topics
            items:
              $ref: '#/definitions/Topic'
        '400':
          description: The request for topic creation was not successful. Further details in the returned response.
          schema:
            $ref: '#/definitions/Problem'
  '/topics/{topic}/events':
    get:
      tags:
        - high-level-api
        - draft
      summary: |
        Starts a stream delivery for the specified partitions of the given topic.
        The tracking of the current position in the partitions and of which
        partitions is being read is in the responsibility of the client.
        No commits are needed.
      parameters:
        - name: topic
          in: path
          description: Topic where to get events from
          type: string
          required: true
        - name: x-nakadi-cursors
          in: header
          description: Cursors pointing to partitions/offsets to start read from
          required: false
          type: array
          items:
            type: string
            format: '#/definitions/Cursor'
        - name: batch_limit
          in: query
          description: |
            Maximum number of `Event`s in each chunk of the stream. If unspecified assumes default value 1
            (i.e. each event is individually submitted). This limit is applied per partition.
          type: integer
          format: int32
          required: false
          default: 1
        - name: stream_limit
          in: query
          description: |
            Maximum number of `Event`s in this stream. If 0 or undefined, will
            stream indefinately.

            Stream initialization will fail if `stream_limit` is lower than
            `batch_limit`.
          type: integer
          format: int32
          required: false
          default: 0
        - name: batch_flush_timeout
          in: query
          description: Maximum time in seconds to wait for the flushing of each chunk; if the `batch_limit` is reached before this time is reached the messages are immediately flushed to the client.
          type: integer
          format: int32
          required: false
        - name: stream_timeout
          in: query
          description: |
            Maximum time in seconds a stream will live before being interrupted.
            If unspecified will stream indefinately.

            If this timeout is reached any pending messages (in the sense of
            `stream_limit`) will be flushed to the client.

            Stream initialization will fail if `stream_timeout` is lower than
            `batch_flush_timeout`.
          type: integer
          format: int32
          required: false
        - name: batch_keep_alive_limit
          in: query
          description: Maximum number of keep-alive messages to get in a row before closing the connection. Unlimited by default.
          type: integer
          format: int32
          required: false
      responses:
        '200':
          description: |
            Starts streaming to the client.
            Stream format is a continuous series of `EventStreamBatch`s separated by `\n`
          schema:
            $ref: '#/definitions/EventStreamFetch'
        '400':
          description: Bad syntax
          schema:
            $ref: '#/definitions/Problem'
        '401':
          description: Not authenticated
          schema:
            $ref: '#/definitions/Problem'
        '404':
          description: Not found. Typically in case of requesting from a non existing topic or partition. Details are provided on the returned `Problem`.
          schema:
            $ref: '#/definitions/Problem'
        '500':
          description: Internal Server Error. Details are provided on the returned `Problem`.
          schema:
            $ref: '#/definitions/Problem'
    post:
      tags:
        - high-level-api
        - draft
      description: |
        Post a one or more `Event`s to a given `Topic`.
        The partition is implicitly controlled by the partitioning_key attribute of the event. Nakadi guarantees that
        all events with the same partitioning_key end up in the same partition.
      parameters:
        - name: topic
          in: path
          description: Topic name where to send events to
          type: string
          required: true
        - name: event
          in: body
          description: The body contains an array of events being sent.
          required: true
          schema:
            type: array
            description: An array of events to be pushed to Nakadi
            items:
              $ref: '#/definitions/Event'
        - name: Content-Encoding
          in: header
          required: false
          description: '"Allow the publisher to gzip compress the payload by setting this header to "gzip". For Example "Content-Encoding: gzip"'
          type: string
      responses:
        '201':
          description: All events are submitted successfully.
        '401':
          description: Not authenticated
          schema:
            $ref: '#/definitions/Problem'
        '403':
          description: Not allowed
          schema:
            $ref: '#/definitions/Problem'
        '422':
          description: Unprocessable Entity
          schema:
            $ref: '#/definitions/Problem'
        '503':
          description: Not available
          schema:
            $ref: '#/definitions/Problem'
  '/topics/{topic}/partitions':
    get:
      tags:
        - monitoring
        - management-api
      summary: Lists the `Partition`s for the given topic
      parameters:
        - name: topic
          in: path
          description: Topic name
          type: string
          required: true
      responses:
        '200':
          description: OK
          schema:
            type: array
            description: An array of `Partition`s
            items:
              $ref: '#/definitions/Partition'
  '/topics/{topic}/partitions/{partition}':
    get:
      tags:
        #- low-level-api
        - management-api
      summary: Returns the given `Partition` of this topic
      parameters:
        - name: topic
          in: path
          description: Topic name
          type: string
          required: true
        - name: partition
          in: path
          description: Partition id.
          type: string
          required: true
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/Partition'

  '/topics/{topic}/partitions/{partition}/events':
    post:
      tags:
        - low-level-api
      summary: |
        Posts a batch of `Event`s to the specified partition of this topic.
        Note that this overwrites the evaluation of the partitioning_key.

        **To be defined:** Every `Event` submitted to a topic will have its content validated and enriched, respectively, by the `EventValidationStrategy` and the `EventEnrichmentStrategy` defined for this `Topic` (see POST /topics for details).
      parameters:
        - name: topic
          in: path
          description: Topic where to send events to.
          type: string
          required: true
        - name: partition
          in: path
          description: Partition where which the events are stored.
          type: string
          required: true
        - name: Content-Encoding
          in: header
          required: false
          description: '"Allow the publisher to gzip compress the payload by setting this header to "gzip". For Example "Content-Encoding: gzip"'
          type: string
        - name: event
          in: body
          description: Array of `Event`s being sent.
          schema:
            type: array
            items:
              $ref: '#/definitions/Event'
      responses:
        '201':
          description: Event submitted.
        '401':
          description: Not authenticated
          schema:
            $ref: '#/definitions/Problem'
        '403':
          description: Not allowed
          schema:
            $ref: '#/definitions/Problem'
        '422':
          description: Unprocessable Entity
          schema:
            $ref: '#/definitions/Problem'
        '503':
          description: Not available
          schema:
            $ref: '#/definitions/Problem'
    get:
      tags:
        - low-level-api
      summary: |
        Starts a stream delivery for the specified partition of the given topic. The events are send in `EventStreamBatch`es.
        The tracking of the current position in the partition and of which
        partition is being read is in the responsibility of the client.
        No commits are needed.
      parameters:
        - name: topic
          in: path
          description: Topic to consume events from
          type: string
          required: true
        - name: partition
          in: path
          description: Id of the partition where to get events from
          type: string
          required: true
        - name: start_from
          in: query
          description: Starting offset of the stream. Must be in the range defined by the `Partition`.
          type: string
          required: true
        - name: batch_limit
          in: query
          description: Maximum number of `EventStreamBatch`s in each chunk of the stream. If unspecified assumes default value 1 (i.e. each event is individually submitted).
          type: integer
          format: int32
          required: false
          default: 1
        - name: stream_limit
          in: query
          description: |
            Maximum number of `Event`s in this stream. If 0 or undefined, will stream indefinately.
            Stream initialization will fail if `stream_limit` is lower than `batch_limit`.
          type: integer
          format: int32
          required: false
        - name: batch_flush_timeout
          in: query
          description: |
            Maximum time in seconds to wait for the flushing of each chunk; if the `batch_limit` is reached before this
            time is reached the messages are immediately flushed to the client.
            A value of 0 will flush every batch events immediatly as soon as they come in.
          type: integer
          format: int32
          required: false
        - name: stream_timeout
          in: query
          description: |
            Maximum time in seconds a stream will live before being interrupted. If unspecified will stream
            indefinately.
            If this timeout is reached any pending messages (in the sense of `stream_limit`) will be flushed to the
            client.
            Stream initialization will fail if `stream_timeout` is lower than `batch_flush_timeout`.
          type: integer
          format: int32
          required: false
        - name: batch_keep_alive_limit
          in: query
          description: |
            Maximum number of keep-alive messages to get in a row
            before closing the connection.
            Unlimited by default.
          type: integer
          format: int32
          required: false
        - name: Accept-Encoding
          in: header
          required: false
          description: '"If set the client requests the body to be gzip compressed. For Example "Content-Encoding: gzip"'
          type: string
      responses:
        '200':
          description: |
            Starts streaming to the client.
            Stream format is a continuous series of `EventStreamBatch`s separated by `\n`
          schema:
            $ref: '#/definitions/EventStreamBatch'
        '400':
          description: Bad syntax
          schema:
            $ref: '#/definitions/Problem'
        '401':
          description: Not authenticated
          schema:
            $ref: '#/definitions/Problem'
        '404':
          description: Not found. Typically in case of requesting from a non existing topic of partition.
          schema:
            $ref: '#/definitions/Problem'
        '500':
          description: Server error. Details are given in the response body.
          schema:
            $ref: '#/definitions/Problem'


# ################################### #
#                                     #
#             Definitions             #
#                                     #
# ################################### #

definitions:
  Event:
    type: object
    description: |
      **To be changed**. This is the most general representation of an event, that can be processed
      by Nakadi.

      It should be used as a base definition for all events, that flow through
      Nakadi by extending attributes of this object type.
    properties:
      event_type:
        type: string
        example: 'https://resource-events.zalando.com/ResourceCreated'
      partitioning_key:
        type: string
        example: 'ABC123XXX-001'
      metadata:
        $ref: '#/definitions/EventMetaData'
  EventMetaData:
    type: object
    properties:
      id:
        type: string
        format: uuid
      created:
        type: string
        format: date-time
      root_id:
        type: string
        format: uuid
      parent_id:
        type: string
        format: uuid
      scopes:
        type: array
        items:
          type: string
  Problem:
    type: object
    required:
      - detail
    properties:
      detail:
        type: string
        description: Problem description
        example: Topic does not exist
  Metrics:
    type: object
  Topic:
    type: object
    required:
      - name
    properties:
      name:
        type: string
        description: Topic name
        example: article.120
  Partition:
    required:
      - partition
      - oldest_available_offset
      - newest_available_offset
    properties:
      partition:
        type: string
      oldest_available_offset:
        type: string
      newest_available_offset:
        type: string
  Cursor:
    required:
      - partition
      - offset
    properties:
      partition:
        type: string
      offset:
        type: string
  EventStreamBatch:
    description: |
      One chunk of events in a stream. A batch consists of an array of `Event`s plus a `Cursor` pointing to the offset of the last Event in the stream.

      The size of the array of Event is limited by the parameters used to initialize a Stream.
    required:
      - cursor
    properties:
      cursor:
        $ref: '#/definitions/Cursor'
      events:
        type: array
        items:
          $ref: '#/definitions/Event'
